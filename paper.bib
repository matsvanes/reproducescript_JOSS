@article{Afgan2018,
  title = {The {{Galaxy}} Platform for Accessible, Reproducible and Collaborative Biomedical Analyses: 2018 Update},
  shorttitle = {The {{Galaxy}} Platform for Accessible, Reproducible and Collaborative Biomedical Analyses},
  author = {Afgan, Enis and Baker, Dannon and Batut, B{\'e}r{\'e}nice and {van~den~Beek}, Marius and Bouvier, Dave and {\v C}ech, Martin and Chilton, John and Clements, Dave and Coraor, Nate and Gr{\"u}ning, Bj{\"o}rn A and Guerler, Aysam and {Hillman-Jackson}, Jennifer and Hiltemann, Saskia and Jalili, Vahid and Rasche, Helena and Soranzo, Nicola and Goecks, Jeremy and Taylor, James and Nekrutenko, Anton and Blankenberg, Daniel},
  year = {2018},
  month = jul,
  journal = {Nucleic Acids Research},
  volume = {46},
  number = {W1},
  pages = {W537-W544},
  issn = {0305-1048, 1362-4962},
  doi = {10.1093/nar/gky379},
  langid = {english},
  file = {/Volumes/T5_OHBA/Literature/Zotero/storage/8U4MEKDI/Afgan et al. - 2018 - The Galaxy platform for accessible, reproducible a.pdf}
}

@article{Andersen2018,
  title = {Group {{Analysis}} in {{FieldTrip}} of {{Time-Frequency Responses}}: {{A Pipeline}} for {{Reproducibility}} at {{Every Step}} of {{Processing}}, {{Going From Individual Sensor Space Representations}} to an {{Across-Group Source Space Representation}}},
  shorttitle = {Group {{Analysis}} in {{FieldTrip}} of {{Time-Frequency Responses}}},
  author = {Andersen, Lau M.},
  year = {2018},
  month = may,
  journal = {Frontiers in Neuroscience},
  volume = {12},
  pages = {261},
  issn = {1662-453X},
  doi = {10.3389/fnins.2018.00261},
  langid = {english},
  file = {/Volumes/T5_OHBA/Literature/Zotero/storage/S68SYQGQ/Andersen - 2018 - Group Analysis in FieldTrip of Time-Frequency Resp.pdf}
}

@misc{Ashburner2020,
  title = {{{SPM12 Manual}}},
  author = {Ashburner, John and Barnes, Gareth and Chen, Chun-Chun and Daunizeau, Jean and Flandin, Guillaume and Friston, Karl and Gitelman, Darren and Volkmar, Glauche and Henson, Rik and Hutton, Chloe and Jafarian, Amirhossein and Kiebel, Stefan and Kilner, James and Litvak, Vladimir and Mattout, J{\'e}r{\'e}mie and Moran, Rosalyn and Penny, Will and Phillips, Christophe and Razi, Adeel and Stephan, Klaas and Tak, Sungho and Tyrer, Ashley and Zeidman, Peter},
  year = {2020},
  file = {/Volumes/T5_OHBA/Literature/Zotero/storage/M3YKJ2FH/manual.pdf}
}

@article{Bellec2012,
  title = {The Pipeline System for {{Octave}} and {{Matlab}} ({{PSOM}}): A Lightweight Scripting Framework and Execution Engine for Scientific Workflows},
  shorttitle = {The Pipeline System for {{Octave}} and {{Matlab}} ({{PSOM}})},
  author = {Bellec, Pierre and {Lavoie-Courchesne}, S{\'e}bastien and Dickinson, Phil and Lerch, Jason P. and Zijdenbos, Alex P. and Evans, Alan C.},
  year = {2012},
  journal = {Frontiers in Neuroinformatics},
  volume = {6},
  issn = {1662-5196},
  doi = {10.3389/fninf.2012.00007},
  abstract = {The analysis of neuroimaging databases typically involves a large number of inter-connected steps called a pipeline. The pipeline system for Octave and Matlab (PSOM) is a flexible framework for the implementation of pipelines in the form of Octave or Matlab scripts. PSOM does not introduce new language constructs to specify the steps and structure of the workflow. All steps of analysis are instead described by a regular Matlab data structure, documenting their associated command and options, as well as their input, output, and cleaned-up files. The PSOM execution engine provides a number of automated services: (1) it executes jobs in parallel on a local computing facility as long as the dependencies between jobs allow for it and sufficient resources are available; (2) it generates a comprehensive record of the pipeline stages and the history of execution, which is detailed enough to fully reproduce the analysis; (3) if an analysis is started multiple times, it executes only the parts of the pipeline that need to be reprocessed. PSOM is distributed under an open-source MIT license and can be used without restriction for academic or commercial projects. The package has no external dependencies besides Matlab or Octave, is straightforward to install and supports of variety of operating systems (Linux, Windows, Mac). We ran several benchmark experiments on a public database including 200 subjects, using a pipeline for the preprocessing of functional magnetic resonance images (fMRI). The benchmark results showed that PSOM is a powerful solution for the analysis of large databases using local or distributed computing resources.},
  langid = {english},
  file = {/Volumes/T5_OHBA/Literature/Zotero/storage/3SQR8NZK/Bellec et al. - 2012 - The pipeline system for Octave and Matlab (PSOM) .pdf}
}

@article{Button2013,
  title = {Power Failure: Why Small Sample Size Undermines the Reliability of Neuroscience},
  shorttitle = {Power Failure},
  author = {Button, Katherine S. and Ioannidis, John P. A. and Mokrysz, Claire and Nosek, Brian A. and Flint, Jonathan and Robinson, Emma S. J. and Munaf{\`o}, Marcus R.},
  year = {2013},
  month = may,
  journal = {Nature Reviews Neuroscience},
  volume = {14},
  number = {5},
  pages = {365--376},
  issn = {1471-003X, 1471-0048},
  doi = {10.1038/nrn3475},
  abstract = {A study with low statistical power has a reduced chance of detecting a true effect, but it is less well appreciated that low power also reduces the likelihood that a statistically significant result reflects a true effect. Here, we show that the average statistical power of studies in the neurosciences is very low. The consequences of this include overestimates of effect size and low reproducibility of results. There are also ethical dimensions to this problem, as unreliable research is inefficient and wasteful. Improving reproducibility in neuroscience is a key priority and requires attention to well-established but often ignored methodological principles.},
  langid = {english},
  file = {/Volumes/T5_OHBA/Literature/Zotero/storage/HTP5D4QF/Button et al. - 2013 - Power failure why small sample size undermines th.pdf}
}

@article{Gilmore2017,
  title = {Progress {{Toward Openness}}, {{Transparency}}, and {{Reproducibility}} in {{Cognitive Neuroscience}}},
  author = {Gilmore, Rick O. and Diaz, Michele T. and Wyble, Brad A. and Yarkoni, Tal},
  year = {2017},
  month = may,
  journal = {Annals of the New York Academy of Sciences},
  volume = {1396},
  number = {1},
  pages = {5--18},
  issn = {0077-8923},
  doi = {10.1111/nyas.13325},
  abstract = {Accumulating evidence suggests that many findings in psychological science and cognitive neuroscience may prove difficult to reproduce; statistical power in brain imaging studies is low, and has not improved recently; software errors in common analysis tools are common, and can go undetected for many years; and, a few large scale studies notwithstanding, open sharing of data, code, and materials remains the rare exception. At the same time, there is a renewed focus on reproducibility, transparency, and openness as essential core values in cognitive neuroscience. The emergence and rapid growth of data archives, meta-analytic tools, software pipelines, and research groups devoted to improved methodology reflects this new sensibility. We review evidence that the field has begun to embrace new open research practices, and illustrate how these can begin to address problems of reproducibility, statistical power, and transparency in ways that will ultimately accelerate discovery.},
  pmcid = {PMC5545750},
  pmid = {28464561},
  file = {/Volumes/T5_OHBA/Literature/Zotero/storage/WN5MRG2R/Gilmore et al. - 2017 - Progress Toward Openness, Transparency, and Reprod.pdf}
}

@article{Gleeson2017,
  title = {A {{Commitment}} to {{Open Source}} in {{Neuroscience}}},
  author = {Gleeson, Padraig and Davison, Andrew P. and Silver, R. Angus and Ascoli, Giorgio A.},
  year = {2017},
  month = dec,
  journal = {Neuron},
  volume = {96},
  number = {5},
  pages = {964--965},
  issn = {08966273},
  doi = {10.1016/j.neuron.2017.10.013},
  langid = {english},
  file = {/Volumes/T5_OHBA/Literature/Zotero/storage/KB4IJRHS/Gleeson et al. - 2017 - A Commitment to Open Source in Neuroscience.pdf}
}

@article{Gorgolewski2011,
  title = {Nipype: {{A Flexible}}, {{Lightweight}} and {{Extensible Neuroimaging Data Processing Framework}} in {{Python}}},
  shorttitle = {Nipype},
  author = {Gorgolewski, Krzysztof and Burns, Christopher D. and Madison, Cindee and Clark, Dav and Halchenko, Yaroslav O. and Waskom, Michael L. and Ghosh, Satrajit S.},
  year = {2011},
  journal = {Frontiers in Neuroinformatics},
  volume = {5},
  issn = {1662-5196},
  doi = {10.3389/fninf.2011.00013},
  abstract = {Current neuroimaging software offer users an incredible opportunity to analyze their data in different ways, with different underlying assumptions. Several sophisticated software packages (e.g., AFNI, BrainVoyager, FSL, FreeSurfer, Nipy, R, SPM) are used to process and analyze large and often diverse (highly multi-dimensional) data. However, this heterogeneous collection of specialized applications creates several issues that hinder replicable, efficient, and optimal use of neuroimaging analysis approaches: (1) No uniform access to neuroimaging analysis software and usage information; (2) No framework for comparative algorithm development and dissemination; (3) Personnel turnover in laboratories often limits methodological continuity and training new personnel takes time; (4) Neuroimaging software packages do not address computational efficiency; and (5) Methods sections in journal articles are inadequate for reproducing results. To address these issues, we present Nipype (Neuroimaging in Python: Pipelines and Interfaces; http://nipy.org/nipype), an open-source, community-developed, software package, and scriptable library. Nipype solves the issues by providing Interfaces to existing neuroimaging software with uniform usage semantics and by facilitating interaction between these packages using Workflows. Nipype provides an environment that encourages interactive exploration of algorithms, eases the design of Workflows within and between packages, allows rapid comparative development of algorithms and reduces the learning curve necessary to use different packages. Nipype supports both local and remote execution on multi-core machines and clusters, without additional scripting. Nipype is Berkeley Software Distribution licensed, allowing anyone unrestricted usage. An open, community-driven development philosophy allows the software to quickly adapt and address the varied needs of the evolving neuroimaging community, especially in the context of increasing demand for reproducible research.},
  langid = {english},
  file = {/Volumes/T5_OHBA/Literature/Zotero/storage/ED2YWSDL/Gorgolewski et al. - 2011 - Nipype A Flexible, Lightweight and Extensible Neu.pdf}
}

@misc{MATLAB2020,
  title = {{{MATLAB}}},
  year = {2020},
  address = {{Natick, Massachusetts}},
  howpublished = {The Mathworks Inc.}
}

@article{Oinn2004,
  title = {Taverna: A Tool for the Composition and Enactment of Bioinformatics Workflows},
  shorttitle = {Taverna},
  author = {Oinn, T. and Addis, M. and Ferris, J. and Marvin, D. and Senger, M. and Greenwood, M. and Carver, T. and Glover, K. and Pocock, M. R. and Wipat, A. and Li, P.},
  year = {2004},
  month = nov,
  journal = {Bioinformatics},
  volume = {20},
  number = {17},
  pages = {3045--3054},
  issn = {1367-4803, 1460-2059},
  doi = {10.1093/bioinformatics/bth361},
  abstract = {Motivation: In silico experiments in bioinformatics involve the co-ordinated use of computational tools and information repositories. A growing number of these resources are being made available with programmatic access in the form of Web services. Bioinformatics scientists will need to orchestrate these Web services in workflows as part of their analyses.},
  langid = {english}
}

@article{Oostenveld2011,
  title = {{{FieldTrip}}: {{Open Source Software}} for {{Advanced Analysis}} of {{MEG}}, {{EEG}}, and {{Invasive Electrophysiological Data}}},
  shorttitle = {{{FieldTrip}}},
  author = {Oostenveld, Robert and Fries, Pascal and Maris, Eric and Schoffelen, Jan-Mathijs},
  year = {2011},
  journal = {Computational Intelligence and Neuroscience},
  volume = {2011},
  pages = {1--9},
  issn = {1687-5265, 1687-5273},
  doi = {10.1155/2011/156869},
  langid = {english},
  file = {/Volumes/T5_OHBA/Literature/Zotero/storage/3NTAMM4G/156869 (1).pdf}
}

@article{OpenScienceCollaboration2015,
  title = {Estimating the Reproducibility of Psychological Science},
  author = {{Open Science Collaboration}},
  year = {2015},
  month = aug,
  journal = {Science},
  volume = {349},
  number = {6251},
  pages = {aac4716-aac4716},
  issn = {0036-8075, 1095-9203},
  doi = {10.1126/science.aac4716},
  langid = {english},
  file = {/Volumes/T5_OHBA/Literature/Zotero/storage/5WAAQWWZ/Open Science Collaboration - 2015 - Estimating the reproducibility of psychological sc.pdf}
}

@article{Pedroni2019,
  title = {Automagic: {{Standardized}} Preprocessing of Big {{EEG}} Data},
  shorttitle = {Automagic},
  author = {Pedroni, Andreas and Bahreini, Amirreza and Langer, Nicolas},
  year = {2019},
  month = oct,
  journal = {NeuroImage},
  volume = {200},
  pages = {460--473},
  issn = {10538119},
  doi = {10.1016/j.neuroimage.2019.06.046},
  abstract = {Electroencephalography (EEG) recordings have been rarely included in large-scale studies. This is arguably not due to a lack of information that lies in EEG recordings but mainly on account of methodological issues. In many cases, particularly in clinical, pediatric and aging populations, the EEG has a high degree of artifact contamination and the quality of EEG recordings often substantially differs between subjects. Although there exists a variety of standardized preprocessing methods to clean EEG from artifacts, currently there is no method to objectively quantify the quality of preprocessed EEG. This makes the commonly accepted procedure of excluding subjects from analyses due to exceeding contamination of artifacts highly subjective. As a consequence, P-hacking is fostered, the replicability of results is decreased, and it is difficult to pool data from different study sites. In addition, in large-scale studies, data are collected over years or even decades, requiring software that controls and manages the preprocessing of ongoing and dynamically growing studies. To address these challenges, we developed Automagic, an open-source MATLAB toolbox that acts as a wrapper to run currently available preprocessing methods and offers objective standardized quality assessment for growing studies. The software is compatible with the Brain Imaging Data Structure (BIDS) standard and hence facilitates data sharing. In the present paper we outline the functionality of Automagic and examine the effect of applying combinations of methods on a sample of resting and task-based EEG data. This examination suggests that applying a pipeline of algorithms to detect artifactual channels in combination with Multiple Artifact Rejection Algorithm (MARA), an independent component analysis (ICA)-based artifact correction method, is sufficient to reduce a large extent of artifacts.},
  langid = {english},
  file = {/Volumes/T5_OHBA/Literature/Zotero/storage/RWZD7D24/Pedroni et al. - 2019 - Automagic Standardized preprocessing of big EEG d.pdf}
}

@misc{Pestilli2017,
  title = {Brainlife},
  author = {Pestilli, Franco and Hayashi, Soichi and Caron, Bradley and {Vinci-Booher}, Sophia},
  year = {2017},
  annotation = {Programmers: \_:n3144}
}

@article{Rex2003,
  title = {The {{LONI Pipeline Processing Environment}}},
  author = {Rex, David E and Ma, Jeffrey Q and Toga, Arthur W},
  year = {2003},
  month = jul,
  journal = {NeuroImage},
  volume = {19},
  number = {3},
  pages = {1033--1048},
  issn = {10538119},
  doi = {10.1016/S1053-8119(03)00185-X},
  abstract = {The analysis of raw data in neuroimaging has become a computationally entrenched process with many intricate steps run on increasingly larger datasets. Many software packages exist that provide either complete analyses or specific steps in an analysis. These packages often possess diverse input and output requirements, utilize different file formats, run in particular environments, and have limited abilities with certain types of data. The combination of these packages to achieve more sensitive and accurate results has become a common tactic in brain mapping studies but requires much work to ensure valid interoperation between programs. The handling, organization, and storage of intermediate data can prove difficult as well. The LONI Pipeline Processing Environment is a simple, efficient, and distributed computing solution to these problems enabling software inclusion from different laboratories in different environments. It is used here to derive a T1-weighted MRI atlas of the human brain from 452 normal young adult subjects with fully automated processing. The LONI Pipeline Processing Environment's parallel processing efficiency using an integrated client/server dataflow model was 80.9\% when running the atlas generation pipeline from a PC client (Acer TravelMate 340T) on 48 dedicated server processors (Silicon Graphics Inc. Origin 3000). The environment was 97.5\% efficient when the same analysis was run on eight dedicated processors.},
  langid = {english},
  file = {/Volumes/T5_OHBA/Literature/Zotero/storage/8VKGJF88/Rex et al. - 2003 - The LONI Pipeline Processing Environment.pdf}
}

@article{Simmons2011,
  title = {False-{{Positive Psychology}}: {{Undisclosed Flexibility}} in {{Data Collection}} and {{Analysis Allows Presenting Anything}} as {{Significant}}},
  shorttitle = {False-{{Positive Psychology}}},
  author = {Simmons, Joseph P. and Nelson, Leif D. and Simonsohn, Uri},
  year = {2011},
  month = nov,
  journal = {Psychological Science},
  volume = {22},
  number = {11},
  pages = {1359--1366},
  issn = {0956-7976, 1467-9280},
  doi = {10.1177/0956797611417632},
  abstract = {In this article, we accomplish two things. First, we show that despite empirical psychologists' nominal endorsement of a low rate of false-positive findings ({$\leq$} .05), flexibility in data collection, analysis, and reporting dramatically increases actual false-positive rates. In many cases, a researcher is more likely to falsely find evidence that an effect exists than to correctly find evidence that it does not. We present computer simulations and a pair of actual experiments that demonstrate how unacceptably easy it is to accumulate (and report) statistically significant evidence for a false hypothesis. Second, we suggest a simple, low-cost, and straightforwardly effective disclosure-based solution to this problem. The solution involves six concrete requirements for authors and four guidelines for reviewers, all of which impose a minimal burden on the publication process.},
  langid = {english},
  file = {/Volumes/T5_OHBA/Literature/Zotero/storage/XKPVG53S/Simmons et al. - 2011 - False-Positive Psychology Undisclosed Flexibility.pdf}
}

@article{Szucs2017,
  title = {Empirical Assessment of Published Effect Sizes and Power in the Recent Cognitive Neuroscience and Psychology Literature},
  author = {Szucs, Denes and Ioannidis, John P. A.},
  year = {2017},
  month = mar,
  journal = {PLoS Biology},
  volume = {15},
  number = {3},
  issn = {1544-9173},
  doi = {10.1371/journal.pbio.2000797},
  abstract = {We have empirically assessed the distribution of published effect sizes and estimated power by analyzing 26,841 statistical records from 3,801 cognitive neuroscience and psychology papers published recently. The reported median effect size was D = 0.93 (interquartile range: 0.64\textendash 1.46) for nominally statistically significant results and D = 0.24 (0.11\textendash 0.42) for nonsignificant results. Median power to detect small, medium, and large effects was 0.12, 0.44, and 0.73, reflecting no improvement through the past half-century. This is so because sample sizes have remained small. Assuming similar true effect sizes in both disciplines, power was lower in cognitive neuroscience than in psychology. Journal impact factors negatively correlated with power. Assuming a realistic range of prior probabilities for null hypotheses, false report probability is likely to exceed 50\% for the whole literature. In light of our findings, the recently reported low replication success in psychology is realistic, and worse performance may be expected for cognitive neuroscience., Biomedical science, psychology, and many other fields may be suffering from a serious replication crisis. In order to gain insight into some factors behind this crisis, we have analyzed statistical information extracted from thousands of cognitive neuroscience and psychology research papers. We established that the statistical power to discover existing relationships has not improved during the past half century. A consequence of low statistical power is that research studies are likely to report many false positive findings. Using our large dataset, we estimated the probability that a statistically significant finding is false (called false report probability). With some reasonable assumptions about how often researchers come up with correct hypotheses, we conclude that more than 50\% of published findings deemed to be statistically significant are likely to be false. We also observed that cognitive neuroscience studies had higher false report probability than psychology studies, due to smaller sample sizes in cognitive neuroscience. In addition, the higher the impact factors of the journals in which the studies were published, the lower was the statistical power. In light of our findings, the recently reported low replication success in psychology is realistic, and worse performance may be expected for cognitive neuroscience.},
  pmcid = {PMC5333800},
  pmid = {28253258},
  file = {/Volumes/T5_OHBA/Literature/Zotero/storage/JCYPKSY2/Szucs and Ioannidis - 2017 - Empirical assessment of published effect sizes and.pdf}
}

@misc{zotero-undefined,
  type = {Misc}
}

@article{Zwaan2017,
  title = {Making {{Replication Mainstream}}},
  author = {Zwaan, Rolf A. and Etz, Alexander and Lucas, Richard E. and Donnellan, M. Brent},
  year = {2017},
  month = oct,
  journal = {Behavioral and Brain Sciences},
  pages = {1--50},
  issn = {0140-525X, 1469-1825},
  doi = {10.1017/S0140525X17001972},
  langid = {english},
  file = {/Volumes/T5_OHBA/Literature/Zotero/storage/ZGV7P6F3/Zwaan e.a. - 2017 - MAKING REPLICATION MAINSTREAM.pdf}
}
